{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Hypothesis Testing \n",
    "\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* Parametric tests\n",
    "    * one-sample t-test\n",
    "    * paired t-test\n",
    "    * two-sample t-test\n",
    "    * ANOVA\n",
    "* Testing parametric assumptions\n",
    "    * Verifying assumptions\n",
    "    * Modifying data \n",
    "* Non-parametric tests\n",
    "    * Signed-rank tests\n",
    "    * Bootstrapping\n",
    "    * Estimation plots using [dabest](https://acclab.github.io/DABEST-python-docs/tutorial.html)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "import os\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import dabest as db\n",
    "\n",
    "# For retina displays only \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "Y = np.random.normal(loc=3, scale=2, size=100)\n",
    "\n",
    "df_one_samp = pd.DataFrame(data = {'Y': Y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excersise: What do you expect for pvalue if popmean = 3? What happens as you move away from 3? \n",
    "\n",
    "sps.ttest_1samp(Y, popmean=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exersise: find p value by using statsmodels and thinking about the test as a model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "X1 = np.random.normal(loc=0, scale=2, size=N)\n",
    "X2 = X1 + np.random.normal(loc=2, scale=1, size=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.ttest_rel(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use ttest_1samp amd show that you get the same result if you do one-way t-test of the difference\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-sample t-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "effect_size = 1 \n",
    "std_dev = 2\n",
    "X1 = np.random.normal(loc=0, scale=std_dev, size=N)\n",
    "X2 = np.random.normal(loc=effect_size, scale=std_dev, size=N)\n",
    "\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2})\n",
    "df_melt = df.melt(value_vars=['X1', 'X2'], var_name='Group', value_name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.ttest_ind(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exersise: find p value by using statsmodels and thinking about the test as a model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "effect_size_2 = 1\n",
    "effect_size_3 = -3\n",
    "std_dev = 2\n",
    "X1 = np.random.normal(loc=0, scale=std_dev, size=N)\n",
    "X2 = np.random.normal(loc=effect_size_2, scale=std_dev, size=N)\n",
    "X3 = np.random.normal(loc=effect_size_3, scale=std_dev, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.f_oneway(X1, X2, X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exersise (tougher): find p value by using statsmodels and thinking about the test as a model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing non-parametic assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Generate some non-gaussian data, make sure you know how to specify the mean of\n",
    "# the population and your sample size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Test it ASSUMING it meets assumptions of parametric tests. \n",
    "# Do you get the correct result?\n",
    "# 1. Play around with sample size, variances, etc. \n",
    "# 2. If you are feeling really into it, draw a graph showing what happens as one population gets \n",
    "# further and further from normal. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Look up one of the following and apply it to your data: \n",
    "# \n",
    "# Data are normally distributed\n",
    "#    D’Agostino-Pearson\n",
    "#    Shapiro-Wilk\n",
    "#    Kolmogorov-Smirnov\n",
    "#    Lilliefors Test\n",
    "# Equal variance between groups\n",
    "#    Levene’s Test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signed-rank tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon sign-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "Y = np.exp(np.random.randn(100))\n",
    "Y = Y - Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data\n",
    "fig, ax = plt.subplots()\n",
    "x, c, _ = ax.hist(Y, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for normality\n",
    "sps.normaltest(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if mean is different from 0 \n",
    "sps.wilcoxon(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using \n",
    "signed_rank_Y = np.sign(Y)*sps.rankdata(Y)\n",
    "sps.ttest_1samp(signed_rank_Y, popmean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_rank_df = pd.DataFrame({'Y': signed_rank_Y})\n",
    "smf.ols(\"Y ~ 1\", data=signed_rank_df).fit().pvalues[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon signed-rank test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "N = 100\n",
    "X1 = np.exp(np.random.normal(loc=0, scale=2, size=N))\n",
    "X2 = X1 + np.random.normal(loc=2, scale=1, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.wilcoxon(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "N = 100\n",
    "X1 = np.exp(np.random.normal(loc=0, scale=2, size=N))\n",
    "X2 = np.exp(np.random.normal(loc=2, scale=1, size=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.mannwhitneyu(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Compare p values obtained using a t-test and a rank test for \n",
    "# NORMAL data that does satisfy parametric assumptions \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping and estimation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.uniform(size=100) - 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b, c, _ = ax.hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excerise: Write a loop to generate N_rep sample means from Y. Uese these to find out a p_value for whether mean differs from 0.\n",
    "\n",
    "N_rep = 2000 \n",
    "sample_means = []\n",
    "for i in range(N_rep):\n",
    "    ???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.random.uniform(size=100) - 0.4\n",
    "Y2 = np.random.uniform(size=100) - 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b, c, _ = ax.hist(Y1)\n",
    "b, c, _ = ax.hist(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Exercise: Write a loop to generate N_rep sample means from Y1 and . Use these to find out a p_value for whether mean differs from 0.\n",
    "\n",
    "N_rep = 2000 \n",
    "sample_means_1 = []\n",
    "sample_means_2 = []\n",
    "for i in range(N_rep):\n",
    "    ???\n",
    "\n",
    "how_often_s1_larger = [s1 > s2 for s1 in sample_means_1 for s2 in sample_means_2]\n",
    "p_value = np.sum(how_often_s1_larger) / len(how_often_s1_larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation plots using [dabest](https://acclab.github.io/DABEST-python-docs/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.random.uniform(size=100) - 0.4\n",
    "Y2 = np.random.uniform(size=100) - 0.2\n",
    "\n",
    "df = pd.DataFrame({'Control 1': Y1, 'Test 1': Y2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired = db.load(df, idx=(\"Control 1\", \"Test 1\"), paired=False, id_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired.mean_diff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired.hedges_g.plot()\n",
    "plt.savefig('./dabest.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (QN)",
   "language": "python",
   "name": "py3-qn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
