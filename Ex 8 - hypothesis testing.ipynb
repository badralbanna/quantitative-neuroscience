{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 8: Hypothesis Testing \n",
    "\n",
    "This exercise will teach you how to do statsitical testing using \n",
    "\n",
    "1. [`scipy.stats`](https://docs.scipy.org/doc/scipy/reference/stats.html): Classic package for most basic statistical testing. \n",
    "2. [`pingouin`](https://docs.scipy.org/doc/scipy/reference/stats.html): A new package extending `scipy.stats` to include more modern approaches. Increasingly integrated into `pandas`\n",
    "3. [`statsmodels`](https://www.statsmodels.org/stable/index.html): A package for statistical modeling. Reproduces much of the functionality included with R including the modeling syntax. \n",
    "4. [`dabest`](https://acclab.github.io/DABEST-python-docs/index.html): Package specifically for bootstrapping analyses. \n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* Parametric tests\n",
    "    * one-sample t-test\n",
    "    * paired t-test\n",
    "    * two-sample t-test\n",
    "    * ANOVA\n",
    "* Testing parametric assumptions\n",
    "    * Verifying assumptions\n",
    "    * Modifying data \n",
    "* Non-parametric tests\n",
    "    * Signed-rank tests\n",
    "    * Bootstrapping\n",
    "    * Estimation plots using [dabest](https://acclab.github.io/DABEST-python-docs/tutorial.html)\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "# Some new stats packages \n",
    "\n",
    "## Basic statistical tests\n",
    "import scipy.stats as sps\n",
    "\n",
    "## New package for statistical testing\n",
    "import pingouin as pg\n",
    "\n",
    "## General statistical modeling \n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "\n",
    "## Non-parametric testing\n",
    "import dabest as db\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametric tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### one-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "Y = np.random.normal(loc=3, scale=2, size=100)\n",
    "\n",
    "df_one_samp = pd.DataFrame(data = {'Y': Y})\n",
    "df_one_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "_ = ax.hist(Y, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating ttest from mean = 3\n",
    "\n",
    "sps.ttest_1samp(Y, popmean=0, alternative=\"greater\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using pingouin to calculate one-sample t-test. Same as the above. \n",
    "\n",
    "pg.ttest(Y, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: What do you expect for pvalue if popmean=3? What happens as you move away from 3? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "X1 = np.random.normal(loc=0, scale=2, size=N)\n",
    "X2 = X1 + np.random.normal(loc=2, scale=1, size=N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=2)\n",
    "ax[0].hist(X1)\n",
    "ax[1].hist(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.ttest_rel(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use ttest_1samp amd show that you get the same result if you do one-way t-test of the difference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two-sample t-test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "effect_size = 1 \n",
    "std_dev = 2\n",
    "X1 = np.random.normal(loc=0, scale=std_dev, size=N)\n",
    "X2 = np.random.normal(loc=effect_size, scale=std_dev, size=N)\n",
    "\n",
    "df = pd.DataFrame({'X1': X1, 'X2': X2})\n",
    "df_melt = df.melt(value_vars=['X1', 'X2'], var_name='Group', value_name='X')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.ttest_ind(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.ttest(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: How does sample size effect the p-value? What about the effect size? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating data \n",
    "N = 100\n",
    "effect_size_2 = 1\n",
    "effect_size_3 = -3\n",
    "std_dev = 2\n",
    "X1 = np.random.normal(loc=0, scale=std_dev, size=N)\n",
    "X2 = np.random.normal(loc=effect_size_2, scale=std_dev, size=N)\n",
    "X3 = np.random.normal(loc=effect_size_3, scale=std_dev, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.f_oneway(X1, X2, X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labs = len(X1)*['X1'] + len(X2)*['X2'] + len(X3)*['X3']\n",
    "vals = list(X1) + list(X2) + list(X3)\n",
    "\n",
    "df = pd.DataFrame({'lab': labs, 'val': vals})\n",
    "\n",
    "pg.anova(data=df, dv='val', between='lab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing non-parametic assumptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Generate some non-gaussian data, make sure you know how to specify the mean of\n",
    "# the population and your sample size\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Test it ASSUMING it meets assumptions of parametric tests. \n",
    "# Do you get the correct result?\n",
    "# 1. Play around with sample size, variances, etc. \n",
    "# 2. If you are feeling really into it, draw a graph showing what happens as one population gets \n",
    "# further and further from normal. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Look up one of the following and apply it to your data: \n",
    "# \n",
    "# Data are normally distributed\n",
    "#    D’Agostino-Pearson\n",
    "#    Shapiro-Wilk\n",
    "#    Kolmogorov-Smirnov\n",
    "#    Lilliefors Test\n",
    "# Equal variance between groups\n",
    "#    Levene’s Test\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-parametric tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Signed-rank tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon sign-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "Y = np.exp(np.random.randn(100))\n",
    "Y = Y - Y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting data\n",
    "fig, ax = plt.subplots()\n",
    "x, c, _ = ax.hist(Y, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for normality using sps\n",
    "sps.normaltest(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing for normality using pingoiun \n",
    "pg.normality(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if mean is different from 0 \n",
    "sps.wilcoxon(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.wilcoxon(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using ttest \n",
    "signed_rank_Y = np.sign(Y)*sps.rankdata(Y)\n",
    "sps.ttest_1samp(signed_rank_Y, popmean=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signed_rank_df = pd.DataFrame({'Y': signed_rank_Y})\n",
    "smf.ols(\"Y ~ 1\", data=signed_rank_df).fit().pvalues[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wilcoxon signed-rank test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "N = 100\n",
    "X1 = np.exp(np.random.normal(loc=0, scale=2, size=N))\n",
    "X2 = X1 + np.random.normal(loc=2, scale=1, size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.wilcoxon(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.wilcoxon(X1, X2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mann-Whitney U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating non-normal data\n",
    "N = 100\n",
    "X1 = np.exp(np.random.normal(loc=0, scale=2, size=N))\n",
    "X2 = np.exp(np.random.normal(loc=2, scale=1, size=N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sps.mannwhitneyu(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg.mwu(X1, X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Compare p values obtained using a t-test and a rank test for \n",
    "# NORMAL data that does satisfy parametric assumptions \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bootstrapping and estimation plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.random.uniform(size=100) - 0.4\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b, c, _ = ax.hist(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Excerise: Write a loop to generate N_rep sample means from Y. Use these to find out a p_value for whether mean differs from 0.\n",
    "\n",
    "N_rep = 2000 \n",
    "sample_means = []\n",
    "for i in range(N_rep):\n",
    "    ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise: Use pg.compute_bootci to generate the confidence interval in the mean\n",
    "\n",
    "pg.compute_bootci(???)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Independant samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.random.uniform(size=100) - 0.4\n",
    "Y2 = np.random.uniform(size=100) - 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "b, c, _ = ax.hist(Y1)\n",
    "b, c, _ = ax.hist(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "# Exercise: Write a loop to generate N_rep sample means from Y1 and . Use these to find out a p_value for whether mean differs from 0.\n",
    "\n",
    "N_rep = 2000 \n",
    "sample_means_1 = []\n",
    "sample_means_2 = []\n",
    "for i in range(N_rep):\n",
    "    ???\n",
    "\n",
    "how_often_s1_larger = [s1 > s2 for s1 in sample_means_1 for s2 in sample_means_2]\n",
    "p_value = np.sum(how_often_s1_larger) / len(how_often_s1_larger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimation plots using [dabest](https://acclab.github.io/DABEST-python-docs/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1 = np.random.uniform(size=100) - 0.4\n",
    "Y2 = np.random.uniform(size=100) - 0.2\n",
    "\n",
    "df = pd.DataFrame({'Control 1': Y1, 'Test 1': Y2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired = db.load(df, idx=(\"Control 1\", \"Test 1\"), paired=False, id_col=\"ID\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired.mean_diff.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_groups_unpaired.hedges_g.plot()\n",
    "plt.savefig('./dabest.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('py3-qn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8427839d926cfa02cf98146f41fa7aa1f3aedf26d017c65310c4e12a8a7b9def"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
