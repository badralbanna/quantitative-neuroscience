{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "py3-qn",
   "display_name": "Python 3 (QN)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Exercise 12: Dimensionality reduction\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "* Linear algebra based methods\n",
    "    * PCA\n",
    "    * jPCA\n",
    "* Information theory based methods\n",
    "    * Granger causality\n",
    "    * ICA \n",
    "    * DCA\n",
    "* Classifier\n",
    "    * SVM\n",
    "\n",
    "## Setup"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sps\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import os\n",
    "\n",
    "# For downloading data from the web\n",
    "import urllib\n",
    "\n",
    "# To load Sabes data\n",
    "from dca.data_util import load_sabes_data\n",
    "\n",
    "# For PCA, ICA\n",
    "from sklearn.decomposition import PCA, FastICA\n",
    "from sklearn.linear_model import Ridge as RR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# For jPCA\n",
    "import jPCA\n",
    "from jPCA.util import load_churchland_data, plot_projections\n",
    "\n",
    "# For Dynamical Component Analysis\n",
    "from dca.dca import DynamicalComponentsAnalysis as DCA\n",
    "\n",
    "# For retina displays only \n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "%matplotlib inline"
   ]
  },
  {
   "source": [
    "## Linear alegbra based methods "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### PCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### PCA on test data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "s1 = 5\n",
    "s2 = 2\n",
    "theta = np.pi / 6\n",
    "\n",
    "X1 = np.random.normal(loc=0, scale=s1, size=N)\n",
    "X2 = np.random.normal(0, s2, N)\n",
    "R = np.array(\n",
    "    [[np.cos(theta), np.sin(theta)], \n",
    "     [-np.sin(theta), np.cos(theta)]])\n",
    "X = np.vstack((X1, X2)).T\n",
    "Y = X@R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'aspect': 'equal'})\n",
    "ax.scatter(Y[:,0], Y[:,1], color='k', alpha=.5, edgecolors='none')\n",
    "ax.set_xlabel(\"Original data dim. 1\")\n",
    "ax.set_ylabel(\"Original data dim. 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_test_model = PCA()\n",
    "pca_test_model.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = pca_test_model.components_\n",
    "print(proj)\n",
    "\n",
    "PCA_1 = np.array(proj[0,:])\n",
    "PCA_2 = np.array(proj[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = pca_test_model.explained_variance_\n",
    "print(f\"The observed variances are {vals},\\nand the corresponding standard deviations are {np.sqrt(vals)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'aspect': 'equal'})\n",
    "ax.scatter(Y[:,0], Y[:,1], alpha=.5, color='k', edgecolor='none')\n",
    "ax.set_xlabel(\"Original data dim. 1\")\n",
    "ax.set_ylabel(\"Original data dim. 2\")\n",
    "ax.arrow(0, 0, *(np.sqrt(vals[0])*PCA_1), width=.1, color='r')\n",
    "ax.arrow(0, 0, *(np.sqrt(vals[1])*PCA_2), width=.1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pca = pca_test_model.transform(Y)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_pca[:,0], np.zeros_like(Y_pca[:,0]), alpha=.5, edgecolor='none')\n",
    "ax.scatter(Y_pca[:,0], Y_pca[:,1], alpha=.05, color='k', edgecolor='none')\n",
    "ax.set_xlabel(\"PC 1\")\n",
    "ax.set_ylabel(\"PC 2\")"
   ]
  },
  {
   "source": [
    "#### PCA on neural data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Due to some combination of simple experimental paradigms and more fundamental unknown principles of cortical processing, the neural data we recorded is often much lower dimensional than the recording dimensionality. This tutorial explores a few different ways of thinking about neural dimensionality. It contrasts DCA with the commonly used PCA.\n",
    "\n",
    "**Run once to download the M1 reaching data** \n",
    "\n",
    "The file is 1.1 GB, so it may take a few minutes to download. This data is from the Sabes lab and is recordings from M1 while a monkey is reaching to different locations on a grid. This is the same data used in the DCA paper. In this tutorial, we won't cross validate the results as was done in the paper to keep things simple.\n",
    "\n",
    "More information and data can be found here:\n",
    "\n",
    "O'Doherty, Joseph E., Cardoso, Mariana M. B., Makin, Joseph G., & Sabes, Philip N. (2017). Nonhuman Primate Reaching with Multichannel Sensorimotor Cortex Electrophysiology [Data set]. Zenodo. http://doi.org/10.5281/zenodo.583331"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabes_path = os.path.join('.', 'data', 'sabes-example-data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once to download data\n",
    "if not os.path.isfile(sabes_path): # check if file was already downloaded\n",
    "    urllib.request.urlretrieve('https://zenodo.org/record/583331/files/indy_20160627_01.mat?download=1', sabes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sabes_data = load_sabes_data(sabes_path, bin_width_s=.05, preprocess=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = sabes_data.keys()\n",
    "print(sabes_data.keys())\n",
    "print(*[(key, sabes_data[key].shape) for key in keys])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M1 data\n",
    "sabes_X = sabes_data['M1']\n",
    "sabes_Xn = sabes_X / sabes_X.std(axis=0, keepdims=True) # normalized version will be used later\n",
    "\n",
    "# Motor output \n",
    "sabes_Y = data['cursor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the data and motor outplut\n",
    "fig, (ax_neural, ax_cursor) = plt.subplots(nrows=2, figsize=(6,9), gridspec_kw={'height_ratios': [1,2]})\n",
    "\n",
    "data_map = ax_neural.imshow(sabes_X[:1200].T, extent=[0, 1199*.05, 0, 108], cmap='gray_r', aspect='auto')\n",
    "ax_neural.set_xlabel('Time (s)')\n",
    "ax_neural.set_ylabel('Neuron')\n",
    "fig.colorbar(data_map, ax=ax_neural)\n",
    "\n",
    "ax_cursor.plot(*sabes_Y[:1200].T, c='k')\n",
    "ax_cursor.set_xlabel('cursor x')\n",
    "ax_cursor.set_ylabel('cursor y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the PCA model for the data \n",
    "pca_model = PCA()\n",
    "pca_model.fit(sabes_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the eigenvalues\n",
    "eig_vals = pca_model.explained_variance_\n",
    "noise = .15 # would be estimated from multiple trials...\n",
    "noise_cutoff = 4*noise/np.sqrt(3)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(eig_vals)\n",
    "ax.axhline(noise_cutoff, color='k', linestyle='dotted')\n",
    "ax.set_ylim(0, eig_vals[0])\n",
    "ax.set_ylabel(\"Eigenvalue\")\n",
    "ax.set_xlabel(\"Dimension #\")\n",
    "\n",
    "num_eigs_to_keep = np.nonzero(eig_vals > noise_cutoff)[0][-1] + 1\n",
    "print(f\"The top {num_eigs_to_keep} are above the noise floor.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the first 4 PCs\n",
    "fig, axs = plt.subplots(nrows=4)\n",
    "for i in range(4):\n",
    "    axs[i].plot(pca_model.components_[i])\n",
    "    axs[i].set_title(f\"PC {i+1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the activity in the first 2 PCAs\n",
    "fig, ax = plt.subplots()\n",
    "sabes_X_pca = pca_model.transform(sabes_X)\n",
    "\n",
    "PCA_1 = sabes_X_pca[:,0]\n",
    "PCA_2 = sabes_X_pca[:,1]\n",
    "\n",
    "ax.plot(PCA_1[:10], PCA_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much of the behavior do these components explain? \n",
    "max_dim = 30\n",
    "lag = 4 # 200ms lag for the neural data for predicting behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = np.arange(1, max_dim+1)\n",
    "var = np.sum(pca_model.explained_variance_)\n",
    "\n",
    "pca1_scores = np.zeros(ds.size)\n",
    "for ii, d in enumerate(ds):\n",
    "    Xd = pca_model.transform(sabes_X)[:, :d]\n",
    "    rr_model = RR(alpha=1e-6)\n",
    "    rr_model.fit(Xd[:-lag], sabes_Y[lag:])\n",
    "    pca1_scores[ii] = r2_score(sabes_Y[lag:], rr_model.predict(Xd[:-lag]))\n",
    "rr_model = RR(alpha=1e-6)\n",
    "rr_model.fit(sabes_X[:-lag], sabes_Y[lag:])\n",
    "max_score = r2_score(sabes_Y[lag:], rr_model.predict(sabes_X[:-lag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ds, np.cumsum(pca_model.explained_variance_)[:ds.size] / var, label='Var. explained')\n",
    "ax.plot(ds, pca1_scores / max_score, label=r'$R^2$')\n",
    "ax.set_ylim(0, 1)\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Projected dimensionality')\n",
    "ax.set_ylabel('0-1 normalized metric')"
   ]
  },
  {
   "source": [
    "### jPCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "**Run once to download the Churchland data**\n",
    "\n",
    "Data and method from Churchland MM et al. (2012)  Structure of neural population dynamics during reaching. Nature. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churchland_path = os.path.join('.', 'data', 'churchland-example-data.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(churchland_path): # check if file was already downloaded\n",
    "    urllib.request.urlretrieve('https://www.dropbox.com/sh/2q3m5fqfscwf95j/AAC7fpAr5Sc3FN--nnZMX3sla/exampleData.mat?dl=1', churchland_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "churchland_data, times = load_churchland_data(churchland_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a jPCA object\n",
    "jpca_model = jPCA.JPCA(num_jpcs=2)\n",
    "projected, full_data_var, pca_var_capt, jpca_var_capt = jpca_model.fit(churchland_data, times=times, tstart=-50, tend=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the projected data\n",
    "plot_projections(projected)"
   ]
  },
  {
   "source": [
    "## Information theory based methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### ICA "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "#### ICA on test data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "s1 = 5\n",
    "s2 = 2\n",
    "theta = np.pi / 6\n",
    "\n",
    "X1 = np.random.normal(loc=0, scale=s1, size=N)\n",
    "X2 = np.random.normal(0, s2, N)\n",
    "R = np.array(\n",
    "    [[np.cos(theta), np.sin(theta)], \n",
    "     [-np.sin(theta), np.cos(theta)]])\n",
    "X = np.vstack((X1, X2)).T\n",
    "Y = X@R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'aspect': 'equal'})\n",
    "ax.scatter(Y[:,0], Y[:,1], color='k', alpha=.5, edgecolors='none')\n",
    "ax.set_xlabel(\"Original data dim. 1\")\n",
    "ax.set_ylabel(\"Original data dim. 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ica_test_model = FastICA()\n",
    "ica_test_model.fit(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ica_test_model.components_\n",
    "print(proj)\n",
    "\n",
    "ICA_1 = np.array(proj[0,:])\n",
    "ICA_1 /= np.sqrt((ICA_1**2).sum())\n",
    "ICA_2 = np.array(proj[1,:])\n",
    "ICA_2 /= np.sqrt((ICA_2**2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(subplot_kw={'aspect': 'equal'})\n",
    "ax.scatter(Y[:,0], Y[:,1], alpha=.5, color='k', edgecolor='none')\n",
    "ax.set_xlabel(\"Original data dim. 1\")\n",
    "ax.set_ylabel(\"Original data dim. 2\")\n",
    "ax.arrow(0, 0, *ICA_1, width=.1, color='r')\n",
    "ax.arrow(0, 0, *ICA_2, width=.1, color='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ica = ica_test_model.transform(Y)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(Y_ica[:,0], np.zeros_like(Y_ica[:,0]), alpha=.5, edgecolor='none')\n",
    "ax.scatter(Y_ica[:,0], Y_ica[:,1], alpha=.05, color='k', edgecolor='none')\n",
    "ax.set_xlabel(\"IC 1\")\n",
    "ax.set_ylabel(\"IC 2\")"
   ]
  },
  {
   "source": [
    "#### Running ICA on neural data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the PCA model for the data \n",
    "ica_model = FastICA()\n",
    "ica_model.fit(sabes_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the first 4 ICs\n",
    "fig, axs = plt.subplots(nrows=4, ncols=2)\n",
    "for i in range(4):\n",
    "    axs[i, 0].plot(ica_model.components_[i])\n",
    "    axs[i, 0].set_title(f\"IC {i+1}\")\n",
    "    axs[i, 1].plot(pca_model.components_[i])\n",
    "    axs[i, 1].set_title(f\"PC {i+1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "### Granger causality "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import grangercausalitytests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_f = 10\n",
    "f = 0.5\n",
    "\n",
    "T = np.linspace(0, T_f, 1000)\n",
    "X1 = np.sin(2*np.pi*f*T) + np.random.normal(0, .2, len(T))\n",
    "X2 = np.sin(2*np.pi*f*(T-.3)) + np.random.normal(0, .2, len(T))\n",
    "\n",
    "Xs = np.vstack((X1, X2)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(T, X1, color='.8', label='X1')\n",
    "ax.plot(T, X2, color='.6', label='X2')\n",
    "ax.set_xlabel('time (s)')\n",
    "ax.set_ylabel('signal (au)')\n",
    "\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grangercausalitytests(Xs, maxlag=50)"
   ]
  },
  {
   "source": [
    "### DCA"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dca_model = DCA(T=10, d=109)\n",
    "dca_model.estimate_data_statistics(X) # only need to estimate this once\n",
    "dca_model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the activity in the first 2 PCAs\n",
    "fig, ax = plt.subplots()\n",
    "X_dca_t = dca_model.transform(X)\n",
    "\n",
    "DCA_1 = X_dca_t[:,0]\n",
    "DCA_2 = X_dca_t[:,1]\n",
    "\n",
    "ax.plot(DCA_1[:10], DCA_2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examining PI \n",
    "pi = np.zeros(ds.size)\n",
    "dca_scores = np.zeros(ds.size)\n",
    "max_pi = dca_model.score() # PI of data with no dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ii, d in enumerate(ds):\n",
    "    dca_model.fit_projection(d=d)\n",
    "    pi[ii] = dca_model.score()\n",
    "    Xd = dca_model.transform(X)\n",
    "    rr_model = RR(alpha=1e-6)\n",
    "    rr_model.fit(Xd[:-lag], Y[lag:])\n",
    "    dca_scores[ii] = r2_score(Y[lag:], rr_model.predict(Xd[:-lag]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ds, pi / max_pi, label='PI')\n",
    "ax.plot(ds, dca_scores / max_score, label=r'$R^2')\n",
    "ax.ylim(0, 1)\n",
    "ax.legend(loc='best')\n",
    "ax.set_xlabel('Projected dimensionality')\n",
    "ax.set_ylabel('0-1 normalized metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}