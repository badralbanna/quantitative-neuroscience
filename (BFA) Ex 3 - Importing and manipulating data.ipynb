{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: Importing and manipulating data\n",
    "\n",
    "In the exercise, we're going to learn how to play with some tools for importing and maipulating data sets. We'll focus on a couple of key file types:\n",
    "\n",
    "* Hierarchical Data Format 5 (HDF5): A format for saving large data sets in a \"hierarchical\" format like folders on your computer. In addition to storing the data itself in an efficient way, this format allows for metadata about the datasets to be embedded in the file itself. [HDF5 website](https://www.hdfgroup.org)\n",
    "* Comma Seperated Value (CSV): Simply a spreadsheet stored as a text file.\n",
    "* JavasSript Object Notation (JSON): A format for saving key value pairs (akin to a Python dictionary). Can open it in any text editor like CSV. [JSON website](https://www.json.org/)\n",
    "\n",
    "Beyond talking about ways to open and access these files directly in python via the standard libraries and numpy, we'll also be talking about two really powerful tools for working with data in python:\n",
    "\n",
    "* Pandas: a fast, powerful, flexible and easy to use open source data analysis and manipulation tool (reproduces much of the functionality of R). [Pandas website](https://pandas.pydata.org)\n",
    "* Xarray:  an open source projectfor working with labelled multi-dimensional arrays. [Xarray website](http://xarray.pydata.org/en/stable/)\n",
    "\n",
    "One great place to get data is \n",
    "\n",
    "* [Collaborative Research in Computational Neuroscience - Data repository](crcns.org): Great resource for published data sets. Need to request access but it is open.  \n",
    "\n",
    "Good to practice with a complete data set _and_ see how other people store, organize, & archive their data.\n",
    "\n",
    "## Really important stuff we probably won't have time for\n",
    "\n",
    "* [Neurodata Without Borders (NWB)](https://www.nwb.org): New open standard for storing all kinds of neuroscience data that should be interoperable between tools. \n",
    "* The [Allen Brain Observatory software development kit (allensdk)](https://allensdk.readthedocs.io/en/latest/install.html) has a lot of really powerful tools as well as access to their data. v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "\n",
    "* [3.1 labeled arrays using `xarray`](#xarray)\n",
    "    * 3.1.1 Constructing a `DataArray`\n",
    "    * 3.1.2 Accessing data array elements\n",
    "    * 3.1.3 Interpolating \n",
    "    * 3.1.4 Math with `DataArray` objects\n",
    "    * 3.1.5 Loading / saving `xarray` objects\n",
    "* [3.2 HDF5 using `h5py`](#HDF5) \n",
    "    * 3.2.1 Loading HDF5 files\n",
    "    * 3.2.2 Navigating HDF5 files\n",
    "    * 3.2.3 Writing to HDF5 files \n",
    "* [3.2(alt) HDF5 using `tables`](#HDF5alt)\n",
    "* [3.3 DataFrames from `pandas`](#pandas)\n",
    "    * 3.4.1 Loading CSV files\n",
    "    * ...\n",
    "* [3.4 Neurodata without borders file format (NWB:N) and python API `pynwb`](#NWB)\n",
    "    * ...\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 labeled arrays using `xarray` <a name=\"xarray\">\n",
    "\n",
    "Very often arrays are objects that have coordinates associated with each of the dimesions (like time or space), but numpy doesn't have a method for storing those coordinates with the arrays. This can get cumbersome and basic operations (like interpolating between two coordinates) becomes more difficult than you would want. `xarray` is a package designed to address these deficiencies in `numpy`. Two main obects `DataArray` and a `DataSet`. \n",
    "\n",
    "[The docs for `xarray` can be found here](http://xarray.pydata.org/en/stable/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Constructing a `DataArray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some coordinates \n",
    "time = np.linspace(0, 20, 401) # in seconds\n",
    "space = np.linspace(-10, 10, 1001) # in centimeters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some function of space and time\n",
    "def height_of_wave(t, x, wavelength=2, speed=.1):\n",
    "    return(np.sin(2*np.pi*(x - speed*t) / wavelength))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating arrays to input into function\n",
    "tv, sv = np.meshgrid(time, space)\n",
    "\n",
    "# calculating values of function at each value of `space` and `time`\n",
    "height = height_of_wave(tv, sv)\n",
    "height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheating a bit to make sure this works...\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "plt.imshow(height, cmap=\"jet\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so now we have three objects that all go together\n",
    "1. The actual data: `height`\n",
    "2. An array representing the `x` coordinate `time`\n",
    "3. An array representing the `y` coordinate `space`\n",
    "\n",
    "**and** an implicit set of units `s` & `cm`. \n",
    "\n",
    "_Wouldn't be nice if there were a way to stroe these in one object? There is! `xr.DataArray`_\n",
    "\n",
    "The syntax for `DataArray` is\n",
    "\n",
    "`xr.DataArray(DATA, dims=TUPLE_OF_DIM_NAMES, coords=DICT_OF_COORDINATE_NAMES_AND_VALUES)`\n",
    "\n",
    "Note that \n",
    "\n",
    "1. The order of the `dims` matters. The first named dim corresponds to axis 0 in your array, the second corresponds to axis 1, etc\n",
    "2. the coords keyword takes a dictionary where the keys are the dims that have been named and the coordinate values as values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Did I do this right?\n",
    "\n",
    "xr_height = xr.DataArray(height, dims=(\"x\", \"t\"), coords={\"x\": space, \"t\": time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look how pretty the readout is when I ask jupyter about `xr_hieght`\n",
    "xr_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are `attributes` all about? A dictionary where you can store whatever additional information you want.\n",
    "xr_height.attrs[\"year\"] = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`xarray` has two special variables that it uses:\n",
    "\n",
    "* `long_name`: a long name for the DataArray\n",
    "* `units`: self-explanatory but note that the DataArray _and_ the coordinates have seperate attributes where you can set each of their units. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting some key attributes\n",
    "\n",
    "xr_height.attrs[\"long_name\"] = \"Height of a travelling wave\"\n",
    "xr_height.attrs[\"units\"] = \"mm\"\n",
    "xr_height.x.attrs[\"units\"] = \"cm\"\n",
    "xr_height.t.attrs[\"units\"] = \"s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see you can find the metadata...\n",
    "xr_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Accessing data array elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having all the coordinate info included with the object means accessing relevant info is much easier. For example if we only had the original trio of numpy arrays and we wanted to find the value of the `height` from the array when `space` = 4 and `time` = 2 we would need to use all three objects: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the value of `height` when `space` = 4 and `time` = 2\n",
    "\n",
    "height[space == 4, time == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you had multiple arrays floating around with their own `space` and `time` this would get challenging fast.\n",
    "\n",
    "To access `DataArray` information you can use multiple methods.\n",
    "\n",
    "1. index the array by position and integer label (just like in numpy)\n",
    "2. `.isel` by dimentional name and integer label\n",
    "3. `.loc` by positional and coordinate label\n",
    "4. `.sel` by dimensional name and coordinate label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going back to the example before when `space` = 4 and `time` = 2.\n",
    "# What location is this in the array?\n",
    "\n",
    "print(np.where(space == 4))\n",
    "print(np.where(time == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ok it is at the index integers 350, 20. So we could pick out that place and time from  `xr_height`\n",
    "# Should see the same value as above pop out. \n",
    "\n",
    "xr_height[700, 40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now `.sel` also uses these integer indexes. Note: isel is a function included\n",
    "# with a `DataArray`. It takes keyword arguments that are the dim names.\n",
    "# Note that I can put these in any order I want and the reader can explicitly \n",
    "# see what 20 and 350 refer to. \n",
    "\n",
    "xr_height.isel(t=40, x=700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now the really cool part is skipping the whole step of finding the index and \n",
    "# just using the coordinate values themselves. Analgous to the above we have\n",
    "# two ways of doing this: without keywords and with. Without keywords is the\n",
    "# `.loc` function. Like traditional indexing it uses subscripting (i.e. [ ])\n",
    "\n",
    "xr_height.loc[4, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Similarly, `.sel` is a function allows you to specify the keywords explictly\n",
    "\n",
    "xr_height.sel(t=2, x=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can even slice **using the coordinate values**. This slice takes all\n",
    "# values of x from 0 to 4 and all values of t from 0 to 2\n",
    "\n",
    "xr_height.loc[0:4, 0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Interpolating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens when you ask one of these magic coordinate methods \n",
    "# to pull a value that's not actually in the set of coordinates?\n",
    "\n",
    "xr_height.loc[4, np.pi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ouch! Python gave us a `KeyError`. That's fair, after all our coordinates \n",
    "# didn't have that key. There's another function which will use surrounding \n",
    "# data and interpolate from that data to the point we want: `.interp` \n",
    "# it follows same conventions as `.sel` in that you have to specify the names \n",
    "# of the coordinates.\n",
    "\n",
    "xr_height.interp(x=4, t=np.pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if this is reasonable...\n",
    "\n",
    "xr_height.loc[4, 3.1:3.2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Math with `DataArray` objects\n",
    "\n",
    "`DataArray` objects have many of the same standard functions `np.array` objects do, but knowledge of te coordinates makes life easier. We'll look at a few examples\n",
    "\n",
    "1. Univariate operations (like `.mean()`) on a index no longer require you to remember which variable was axis 0. You can just use the coordinate names to specify which dimension you want to averate over. \n",
    "2. Bivariate operations (like `*`) will automatically do what ever makes sense based on whether the axes line up or not! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taking the overall mean works as before...\n",
    "\n",
    "xr_height.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Averaging over the x direction only:\n",
    "\n",
    "xr_height.mean(dim='x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To think about the math we're going to create a new DataArray that only has a spatial dimension but no time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a linear offset\n",
    "\n",
    "height_offset = xr.DataArray(.05*space, dims=(\"x\",), coords={\"x\": space})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xr_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What should adding these two do? Adding the arrays would crash and burn \n",
    "# because they have different numbers of dimension\n",
    "\n",
    "new_height = xr_height + height_offset\n",
    "new_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Huh? This worked? What did it do? \n",
    "\n",
    "# Here's the original\n",
    "plt.imshow(xr_height, cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the new one.\n",
    "plt.imshow(new_height, cmap='jet')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What did `+` do?**\n",
    "\n",
    "It added the offset to the `x` dimension and did it for each `t`! This makes sense!\n",
    "\n",
    "There is a lot more here, but the key is that math can be simpler. For example, it uses the coordinate information for proper matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that `x` is the shared dimension so it should dissapear after matrix\n",
    "# multiplication. \n",
    "\n",
    "xr_height @ height_offset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Loading / saving `xarray` objects: NetCDF, JSON, Pickle\n",
    "\n",
    "`xarray` natively saves to the [NetCDF (Network Common Data Format)](https://www.unidata.ucar.edu/software/netcdf/docs/faq.html#What-Is-netCDF). This is a format that was originally created for climate science. Under the hood it is using a more general format which we will talk more about [Hierarchical Data Format (HDF)](https://portal.hdfgroup.org/display/HDF5/HDF5).\n",
    "\n",
    "Can convert a `DataArray` to a dictionary and save it using pythons `pickle` package or as a `JSON` file. `JSON` stands for a  JavasSript Object Notation (JSON) it's a text format for saving key value pairs (akin to a Python dictionary). [JSON website](https://www.json.org/)\n",
    "\n",
    "Can also convert it to `pandas` variables (something we'll talk about a bit later), but pandas knows how to save to **many** other formats. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1, Saving the array as a NetCDF file...\n",
    "import os\n",
    "\n",
    "xr_height.to_netcdf(os.path.join(\"data\", \"height.nc\"), format='NETCDF4', engine='netcdf4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ASIDE: It's secretly an HDF5 file\n",
    "# The 'r' here stands for 'read'. Could have just as easily been 'w' for write or 'a' for append. \n",
    "\n",
    "import h5py\n",
    "\n",
    "h5_height = h5py.File(os.path.join(\"data\", \"height.nc\"), 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in h5_height:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and checking that this worked.\n",
    "\n",
    "xr.open_dataarray(os.path.join(\"data\", \"height.nc\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2, converting to a dictionary...\n",
    "\n",
    "dict_height = xr_height.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_height.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...saving dictionary as a pickle...\n",
    "import pickle\n",
    "\n",
    "with open(os.path.join(\"data\", \"height.pickle\"), 'wb') as f:\n",
    "    pickle.dump(dict_height, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...and checking whether it worked. \n",
    "\n",
    "with open(os.path.join(\"data\", \"height.pickle\"), 'rb') as f:\n",
    "    dict_height_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_height_2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3, converting to a dictionary and saving as JSON\n",
    "\n",
    "import json\n",
    "\n",
    "with open(os.path.join(\"data\", \"height.json\"), 'w') as f:\n",
    "    json.dump(dict_height, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"data\", \"height.json\"), 'r') as f:\n",
    "    dict_height_2 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_height_2.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 HDF5 using `h5py`\n",
    "\n",
    "Heirarchical data format is a fomat for storing data in groups with appended metadata. [The docs for h5py can be found here.](https://docs.h5py.org/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Loading HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the HDF5 file into python as `data`.\n",
    "# The 'r' here stands for 'read'. Could have just as easily been 'w' for write or 'a' for append. \n",
    "\n",
    "data = h5py.File(\"data/dataset_2017_08_25_postrun/2017-08-25_09-50-43.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To see all the data use the .visit function \n",
    "\n",
    "data.visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Navigating HDF5 files <a name=\"HDF\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = data[\"ephys/TT1/spikes/times\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's going on here?\n",
    "\n",
    "spikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to cast to array\n",
    "\n",
    "spikes_arr = np.array(spikes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(spikes_arr[:100], 100*[1], s='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Writing to HD5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `a` = append\n",
    "\n",
    "h5file = h5py.File(os.path.join(\"data\", \"my_data.h5\"), mode=\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a group\n",
    "\n",
    "group = h5file.create_group(\"/cell_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some fake data \n",
    "\n",
    "time = np.linspace(0, 100, 1000)\n",
    "voltage = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving these as arrays in the hdf5 file\n",
    "\n",
    "group.create_dataset(\"voltage\", data=voltage)\n",
    "group[\"voltage\"].attrs[\"units\"] = \"mV\"\n",
    "group.create_dataset(\"time\", data=time)\n",
    "group[\"time\"].attrs[\"units\"] = \"s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file.visit(print)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to close a file when you are done!\n",
    "\n",
    "h5file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2(alt) HDF5 using `tables` <a name=\"HDF5alt\">\n",
    "\n",
    "The `pytables` package is a  robust way to interact with HDF5 files. [You can find the package website here](https://www.pytables.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Loading HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the HDF5 file into python as `data`.\n",
    "# The 'r' here stands for 'read'. Could have just as easily been 'w' for write or 'a' for append. \n",
    "\n",
    "data = tables.File(\"data/dataset_2017_08_25_postrun/2017-08-25_09-50-43.hdf5\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To have tables spit out the whole kit and caboodle  \n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"ephys/TT24/spikes\"].visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Navigating HDF5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.root.?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spikes = data.root.ephys.TT1.spikes.times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(spikes[:100], 100*[1], s='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Writing to HD5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file = tables.open_file(\"data/my_data.h5\", mode=\"a\", title=\"My test file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a group\n",
    "\n",
    "group = h5file.create_group(\"/\", 'cell_1', 'Data from cell_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making some fake data \n",
    "\n",
    "time = np.linspace(0, 100, 1000)\n",
    "voltage = np.random.rand(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving these as arrays in the hdf5 file\n",
    "\n",
    "h5file.create_array(group, 'time', time, \"time (ms)\")\n",
    "h5file.create_array(group, 'voltage', voltage, \"voltage (mV)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also create tables with columns of different types\n",
    "# Definiing the information you'd like in your table, and creating an empty table\n",
    "\n",
    "class my_ephys(tables.IsDescription):\n",
    "    time  = tables.Float32Col()      # Signed 64-bit integ\n",
    "    voltage = tables.Float32Col()\n",
    "    \n",
    "table = h5file.create_table(group, 'my_data', my_ephys, \"recording session\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "moment = table.row\n",
    "for i, j in zip(time, voltage):\n",
    "    moment['time']  = i\n",
    "    moment['voltage'] = j\n",
    "    moment.append()\n",
    "\n",
    "table.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving metadata\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 DataFrames from `pandas` <a name=\"pandas\">\n",
    "\n",
    "We're going to be working through [the `pandas` tutorials here.](https://pandas.pydata.org/pandas-docs/stable/getting_started/intro_tutorials/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Creating a `DataFrame` object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Feed `DataFrame` a dictionary where keys are columns and values are a list of\n",
    "# values\n",
    "\n",
    "dict_data = {\"Name\": [\"Braund, Mr. Owen Harris\",  \"Allen, Mr. William Henry\", \"Bonnell, Miss. Elizabeth\"],\n",
    "             \"Age\": [22, 35, 58], \n",
    "             \"Sex\": [\"male\", \"male\", \"female\"]}\n",
    "\n",
    "df = pd.DataFrame(dict_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>58</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name  Age     Sex\n",
       "0   Braund, Mr. Owen Harris   22    male\n",
       "1  Allen, Mr. William Henry   35    male\n",
       "2  Bonnell, Miss. Elizabeth   58  female"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Owen</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>William</td>\n",
       "      <td>35</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age   Sex\n",
       "0     Owen   22   NaN\n",
       "1  William   35  male"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2, a list of dictionary objects, note what it does for the missing \n",
    "# \"sex\" for \"Owen\"\n",
    "\n",
    "option_2 = [{\"Name\": \"Owen\", \"Age\": 22}, {\"Name\": \"William\", \"Age\": 35, \"Sex\":'male'}]\n",
    "pd.DataFrame(option_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xr_height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e197f37aad38>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Option 3, just go directly to a dataframe from another object type...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mxr_height\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'xr_height' is not defined"
     ]
    }
   ],
   "source": [
    "# Option 3, just go directly to a dataframe from another object type...\n",
    "\n",
    "xr_height.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Selecting subsets of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Braund, Mr. Owen Harris\n",
       "1    Allen, Mr. William Henry\n",
       "2    Bonnell, Miss. Elizabeth\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Allen, Mr. William Henry\n",
       "2    Bonnell, Miss. Elizabeth\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 1\n",
    "df[df[\"Age\"] > 25][\"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    Allen, Mr. William Henry\n",
       "2    Bonnell, Miss. Elizabeth\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Option 2\n",
    "# df.loc[THE_rows_I_want, THE_columns_I_want]\n",
    "\n",
    "df.loc[df[\"Age\"] > 25, \"Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, Name    Braund, Mr. Owen Harris\n",
      "Age                          22\n",
      "Sex                        male\n",
      "Name: 0, dtype: object)\n",
      "(1, Name    Allen, Mr. William Henry\n",
      "Age                           35\n",
      "Sex                         male\n",
      "Name: 1, dtype: object)\n",
      "(2, Name    Bonnell, Miss. Elizabeth\n",
      "Age                           58\n",
      "Sex                       female\n",
      "Name: 2, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "for entry in df.iterrows():\n",
    "    print(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Importing data from a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "labcap_df = pd.read_csv(os.path.join(\"data\", \"WID_Data_sh_simple.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>labsh_US</th>\n",
       "      <th>labsh_FR</th>\n",
       "      <th>labsh_CN</th>\n",
       "      <th>capsh_US</th>\n",
       "      <th>capsh_FR</th>\n",
       "      <th>capsh_CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  labsh_US  labsh_FR  labsh_CN  capsh_US  capsh_FR  capsh_CN\n",
       "0    1870       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "1    1871       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "2    1872       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "3    1873       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "4    1874       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "..    ...       ...       ...       ...       ...       ...       ...\n",
       "293  2014       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "294  2015       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "295  2016       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "296  2017       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "297  2018       NaN       NaN       NaN       NaN       NaN       NaN\n",
       "\n",
       "[298 rows x 7 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labcap_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_df = pd.read_csv(os.path.join(\"data\", \"WID_Data_other_simple.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>ind_ann_w_US</th>\n",
       "      <th>ind_ann_w_FR</th>\n",
       "      <th>ind_ann_w_CN</th>\n",
       "      <th>ind_w_i_rat_US</th>\n",
       "      <th>ind_w_i_rat_FR</th>\n",
       "      <th>ind_w_i_rat_CN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1874</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>2014</td>\n",
       "      <td>237269.7416</td>\n",
       "      <td>210355.7484</td>\n",
       "      <td>78452.8705</td>\n",
       "      <td>4.764146</td>\n",
       "      <td>6.06172</td>\n",
       "      <td>6.937985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>2015</td>\n",
       "      <td>243299.4455</td>\n",
       "      <td>207028.8245</td>\n",
       "      <td>85081.7849</td>\n",
       "      <td>4.824684</td>\n",
       "      <td>5.91449</td>\n",
       "      <td>7.104637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Year  ind_ann_w_US  ind_ann_w_FR  ind_ann_w_CN  ind_w_i_rat_US  \\\n",
       "0    1870           NaN           NaN           NaN             NaN   \n",
       "1    1871           NaN           NaN           NaN             NaN   \n",
       "2    1872           NaN           NaN           NaN             NaN   \n",
       "3    1873           NaN           NaN           NaN             NaN   \n",
       "4    1874           NaN           NaN           NaN             NaN   \n",
       "..    ...           ...           ...           ...             ...   \n",
       "293  2014   237269.7416   210355.7484    78452.8705        4.764146   \n",
       "294  2015   243299.4455   207028.8245    85081.7849        4.824684   \n",
       "295  2016           NaN           NaN           NaN             NaN   \n",
       "296  2017           NaN           NaN           NaN             NaN   \n",
       "297  2018           NaN           NaN           NaN             NaN   \n",
       "\n",
       "     ind_w_i_rat_FR  ind_w_i_rat_CN  \n",
       "0               NaN             NaN  \n",
       "1               NaN             NaN  \n",
       "2               NaN             NaN  \n",
       "3               NaN             NaN  \n",
       "4               NaN             NaN  \n",
       "..              ...             ...  \n",
       "293         6.06172        6.937985  \n",
       "294         5.91449        7.104637  \n",
       "295             NaN             NaN  \n",
       "296             NaN             NaN  \n",
       "297             NaN             NaN  \n",
       "\n",
       "[298 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = labcap_df.merge(other_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv(os.path.join(\"data\", \"my_big_data_frame.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Creating new columns from old columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Neurodata without borders file format (NWB:N) and python API pynwb <a name=\"NWB\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynwb import NWBHDF5IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (QN)",
   "language": "python",
   "name": "py3-qn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
